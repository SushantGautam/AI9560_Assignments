{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc36760-89bb-44eb-9bea-a04b6705229d",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af6770b7-ce71-4d2b-b4d6-0d107e2768c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "438d15b2-2da6-4991-98bf-bd63086b60e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>captions</th>\n",
       "      <th>ASR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>Shots on target</td>\n",
       "      <td>Player hears the fans clapping his superb goal...</td>\n",
       "      <td>Chelsea has recovered again in the final third...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Corner kick. Player (Away-Team) is ready to se...</td>\n",
       "      <td>Tripper. Ready to strike. There goes Trippier'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>Shots off target</td>\n",
       "      <td>A cross by Player (Home-Team) from the side of...</td>\n",
       "      <td>There's Hazard. Hazard made a good move toward...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>Throw-in</td>\n",
       "      <td>Player (Home-Team) takes a first-time shot fro...</td>\n",
       "      <td>Diego Costa anticipates. Jones can score. It e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>160</td>\n",
       "      <td>Shots on target</td>\n",
       "      <td>Player (Home-Team) picks up a pass, lines up a...</td>\n",
       "      <td>He wants those races, even if it's towards the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id             label                                           captions  \\\n",
       "0   36   Shots on target  Player hears the fans clapping his superb goal...   \n",
       "1   44            Corner  Corner kick. Player (Away-Team) is ready to se...   \n",
       "2   57  Shots off target  A cross by Player (Home-Team) from the side of...   \n",
       "3   74          Throw-in  Player (Home-Team) takes a first-time shot fro...   \n",
       "7  160   Shots on target  Player (Home-Team) picks up a pass, lines up a...   \n",
       "\n",
       "                                                 ASR  \n",
       "0  Chelsea has recovered again in the final third...  \n",
       "1  Tripper. Ready to strike. There goes Trippier'...  \n",
       "2  There's Hazard. Hazard made a good move toward...  \n",
       "3  Diego Costa anticipates. Jones can score. It e...  \n",
       "7  He wants those races, even if it's towards the...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vQMaaNO_0JU-A2gdSyJpF-WEjJGqWqZdIIp9g9gHGpTdJ3G8l6BvV1PvtmrB3nUTHxnDC_zbiAp3sJx/pub?gid=353977511&single=true&output=csv\")\n",
    "df.rename(columns={'Unnamed: 0': 'id', \"_comments_ASR_unfiltered\": \"ASR\"}, inplace=True)\n",
    "df = df[['id', 'label', 'captions', 'ASR']]\n",
    "exclude_id  =[60580, 80644, 80662, 80670, 80685, 80716, 114392, 114403, 114409, 114410]\n",
    "df = df[~df['id'].isin(exclude_id)]\n",
    "df = df[df['label'].isin(['Shots on target', 'Shots off target', 'Foul', 'Corner', 'Throw-in'])]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca438cac-0aca-4c45-8462-c2af89448749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel, WhisperForAudioClassification\n",
    "import torch\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from torchaudio.transforms import Resample\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from transformers import AutoFeatureExtractor, WhisperModel\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018cac61-d219-4bb3-b283-2ef5c24e96f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\").to(device)\n",
    "\n",
    "# # column_type = \"ASR\"   #ASR, captions\n",
    "# for  column_type in [\"ASR\", \"captions\"]:\n",
    "#   captions = df[column_type].tolist()# max_len = 0\n",
    "\n",
    "#   all_embeddings = torch.empty((0,model.config.hidden_size, )).cpu() #model.config.max_position_embeddings\n",
    "#   batch_size = 256 \n",
    "\n",
    "#   for i in tqdm(range(0, len(captions), batch_size), desc=\"Processing captions\"):\n",
    "#       batch_captions = captions[i:i+batch_size]\n",
    "#       inputs = tokenizer(batch_captions, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "      \n",
    "#       inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "      \n",
    "#       with torch.no_grad():\n",
    "#           outputs = model(**inputs)\n",
    "      \n",
    "#       all_embeddings = torch.cat((all_embeddings, outputs.pooler_output.cpu()), dim=0)\n",
    "\n",
    "#   all_embeddings_cpu = all_embeddings\n",
    "#   print(all_embeddings_cpu.shape)\n",
    "#   torch.save((all_embeddings_cpu,df[\"id\"].tolist()) , column_type+ \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9555893-4a3a-411a-a2b9-fda2b8e45b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Whisper model and the feature extractor\n",
    "model_audio = WhisperModel.from_pretrained(\"openai/whisper-base\")\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"openai/whisper-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91dac19d-61a7-4745-838a-e8efe441623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, folder_path, file_paths):\n",
    "        self.folder_path = folder_path\n",
    "        self.file_paths = file_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        global resampled_audio_padded, resampled_audio\n",
    "        file_path = os.path.join(self.folder_path, self.file_paths[idx])\n",
    "        file_idx = int(file_path.split(\"/\")[-1].split(\"_\")[0])\n",
    "        # filter\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "        resampler = Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "        resampled_audio = resampler(waveform).mean(dim=0)\n",
    "        return file_idx, feature_extractor(resampled_audio, sampling_rate=16000, return_tensors=\"pt\").input_features.squeeze(0)\n",
    "\n",
    "def batch_process(folder_path,  batch_size=64, _start_idx= []):\n",
    "    global features_tensor, pooled_outputs, pooled_outputs, outputs, all_features, batch, decoder_input_ids\n",
    "    video_files = [f for f in os.listdir(folder_path) if f.endswith('.mp4')]\n",
    "    video_ids = [f.split('_')[0]+\"_\" for f in video_files]\n",
    "    filtered_video_files = [f for f, idx in zip(video_files, video_ids) if idx in _start_idx]\n",
    "    filtered_video_files.sort(key=lambda x: int(x.split('_')[0]))    \n",
    "    dataset = AudioDataset(folder_path, filtered_video_files)\n",
    "    print(f\"Dataset size: {len(dataset)}\")\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "    \n",
    "    all_features = []\n",
    "    all_idx = []\n",
    "    for file_idxs, batch in tqdm(data_loader, desc=\"Processing batches\"):\n",
    "        decoder_input_ids = (torch.tensor([1]) * model_audio.config.decoder_start_token_id).repeat(len(batch), 1)\n",
    "        with torch.no_grad():\n",
    "            outputs = model_audio(batch, decoder_input_ids=decoder_input_ids).encoder_last_hidden_state\n",
    "            pooled_outputs = torch.mean(outputs, dim=1).cpu().numpy() # pooling\n",
    "            all_features.extend(pooled_outputs)\n",
    "            all_idx.extend(file_idxs.numpy())\n",
    "  \n",
    "    final_tensor = torch.tensor(np.array(all_features))\n",
    "    print(final_tensor.shape)\n",
    "    torch.save((final_tensor,all_idx) , 'processed_audio_features.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19560f8d-a58a-4d6a-b488-67b86000dfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 7310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 115/115 [2:03:38<00:00, 64.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7310, 512])\n"
     ]
    }
   ],
   "source": [
    "starting_indices_ = list(df['id'].apply(lambda x: str(x) + \"_\").values)\n",
    "# exclude_id  =[\"60580_\", \"80644_\", \"80662_\", \"80670_\", \"80685_\", \"80716_\", \"114392_\", \"114403_\", \"114409_\", \"114410_\"]\n",
    "# starting_indices = list(set(starting_indices_)-set(exclude_id))\n",
    "batch_process('/home/sushant/D1/MyDataSets/SN_Chunks_1ECapASR_10k', batch_size=64, _start_idx=starting_indices_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86983ede-1525-41ea-9512-8b1ad758bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# import os\n",
    "\n",
    "# def is_ffmpeg_callable(filename):\n",
    "#     try:\n",
    "#         waveform, sample_rate = torchaudio.load(filename)\n",
    "#         return True\n",
    "#     except TypeError:\n",
    "#         return False\n",
    "\n",
    "# directory ='/home/sushant/D1/MyDataSets/SN_Chunks_1ECapASR_10k/'\n",
    "# non_callable_files = []\n",
    "\n",
    "\n",
    "# video_files = [f for f in os.listdir(directory) if f.endswith('.mp4')]\n",
    "# video_ids = [f.split('_')[0]+\"_\" for f in video_files]\n",
    "# filtered_video_files = [f for f, idx in zip(video_files, video_ids) if idx in starting_indices]\n",
    "# filtered_video_files.sort(key=lambda x: int(x.split('_')[0]))  \n",
    "# for filepath in filtered_video_files:\n",
    "#     filepath = directory+ filepath\n",
    "#     if os.path.isfile(filepath):\n",
    "#         if not is_ffmpeg_callable(filepath):\n",
    "#             non_callable_files.append(filepath)\n",
    "\n",
    "# print(\"Files not callable with ffmpeg get_src_stream_info:\")\n",
    "# for file in non_callable_files:\n",
    "#     print(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
